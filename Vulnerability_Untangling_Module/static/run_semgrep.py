from pathlib import Path
import json
import re
import subprocess
import os
import shutil
from concurrent.futures import ProcessPoolExecutor
import concurrent.futures
import multiprocessing

#Define project directories
project_root = Path(__file__).resolve().parents[2]
module_path = project_root / "Vulnerability_Untangling_Module"
root_path = module_path / "static"
data_path = project_root / "Raw_Data_Crawling" / "github" / "files_before"

def is_valid_pattern(s):
    """
    Checks whether a string starts with a numeric value followed by a pipe (┆).
    """
    pattern = re.compile(r'^\d+\┆')
    return bool(pattern.match(s))

def is_valid_pattern_1(s):
    """
    Checks whether a string starts with non-numeric, non-whitespace characters
    after leading spaces (used to identify issue descriptions in semgrep output).
    """
    pattern = re.compile(r'       [^0-9\s]+')
    return bool(pattern.match(s))

def extract_numbers_before_pipe(s):
    """
    Extracts all numbers appearing before a pipe (┆) in the given string.

    Parameters:
        s (str): Input string containing semgrep line numbers.

    Returns:
        list[int]: List of extracted line numbers.
    """
    pattern = re.compile(r'(\d+)┆')
    matches = pattern.findall(s)
    return [int(match) for match in matches]

def extract_addresses(input_str, language='java'):
    """
    Extracts and reconstructs semgrep issue descriptions from the command output.

    Parameters:
        input_str (str): Full semgrep CLI output text.
        language (str): Programming language of the scanned file (default 'java').

    Returns:
        list[str]: List of issue descriptions grouped by finding.
    """
    lines = input_str.rstrip().split('\n')
    result = []
    true_i = 7

    #Parse each relevant line group representing an issue
    for i in range(7, len(lines)):
        if i != true_i:
            continue
        if lines[i].strip() == '':
            true_i = i + 1
            continue
        #Match issue header lines
        if is_valid_pattern_1(lines[i]):
            tmp = lines[i]
            j = i + 1
            while True:
                if lines[j].strip().startswith('Details: http'):
                    tmp += '\n' + lines[j]
                    break
                else:
                    tmp += '\n' + lines[j]
                    j += 1
            result.append(tmp)
            true_i = j + 1
        #Match autofix suggestions
        elif lines[i].strip().startswith('▶▶┆ Autofix ▶'):
            tmp = ''
            j = i
            while True:
                if j == len(lines) - 1:
                    tmp += lines[j]
                    break
                if lines[j].strip().startswith('⋮┆----------------------------------------'):
                    break
                tmp += '\n' + lines[j]
                j += 1
            result.append(tmp)
            true_i = j + 1
        #Match line-numbered issues
        elif is_valid_pattern(lines[i].strip()):
            tmp = ''
            j = i
            while True:
                print(f'lines={len(lines)}')
                print(f'j={j}')
                if j == len(lines) - 1:
                    tmp += lines[j]
                    break
                if lines[j].strip().startswith('⋮┆----------------------------------------'):
                    break
                tmp += '\n' + lines[j]
                j += 1
            result.append(tmp)
            true_i = j + 1

    #Combine context and issue lines for complete entries
    adapt_result = []
    for i in reversed(range(len(result))):
        if is_valid_pattern(result[i].strip()) or result[i].strip().startswith('▶▶┆ Autofix ▶'):
            for j in reversed(range(i)):
                if is_valid_pattern_1(result[j]):
                    tmp = result[j] + '\n' + result[i]
                    adapt_result.append(tmp)
                    break

    return adapt_result

def process_content(lock, language, file_name, write_name, idx, content_line):
    """
    Processes a single record from the JSONL file by running semgrep static analysis
    on each file, checking if detected issues fall within modified lines, and saving results.

    Parameters:
        lock (multiprocessing.Manager.Lock): Lock object for thread-safe file writes.
        language (str): Programming language of the analyzed files.
        file_name (str | Path): Path to the input JSONL file.
        write_name (str | Path): Path to the output JSONL file where results are appended.
        idx (int): Index of the current record (used for progress tracking).
        content_line (str): One JSON line from the input file representing a code change record.

    Input files:
        Raw_Data_Crawling/github/files_before/<file_path> - original source file

    Output files:
        Vulnerability_Untangling_Module/output/semgrep/<language>_new.jsonl - file with analysis results
    """
    #Define language extensions
    if language == 'c':
        language_choice = ['c', 'h']
    elif language == 'cpp':
        language_choice = ['cpp', 'h', 'cc']
    elif language == 'java':
        language_choice = ['java']
    elif language == 'python':
        language_choice = ['py']

    record_dict = json.loads(content_line)
    details = record_dict['details']

    #Process each file detail entry
    for idx1, detail in enumerate(details):
        if not detail['file_language'].lower().strip() in language_choice:
            continue

        file_path = detail['file_path']
        file_language = detail['file_language']
        patch = detail['patch']

        #Extract changed line numbers from patch
        pattern = re.compile(r'@@ -(\d+),?(\d*) \+(\d+),?(\d*) @@')
        matches = pattern.findall(patch)
        
        patch_old_line = []
        for match in matches:
            old_start, old_lines, new_start, new_lines = int(match[0]), match[1], int(match[2]), match[3]
            old_lines = int(old_lines) if old_lines else 0
            new_lines = int(new_lines) if new_lines else 0
            patch_old_line.append([old_start, old_lines])

        #Prepare temporary file paths
        real_path = f'{data_path}/{file_path[6:]}'.replace('\\', '/')
        after_real_path = f"{root_path}/tmp/{file_path[6:].replace('\\', '_').replace('/', '_')}.{file_language}"

        if not os.path.exists(real_path):
            print('No path exists!', real_path)
            continue

        shutil.copy(real_path, after_real_path)

        #Run semgrep analysis
        if file_language in ['py', 'java', 'c', 'cc', 'cpp', 'h']:
            is_find = False
            find_message = []
            cppcheck_command = [
                "semgrep", "scan",
                "--config", "auto",
                "-q",
                "--max-lines-per-finding=0",
                after_real_path
            ]
            cppcheck_result = subprocess.run(
                cppcheck_command, shell=True,
                stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                text=True, errors='ignore'
            )

            #Remove temp file
            if os.path.exists(after_real_path):
                os.remove(after_real_path)

            #Process semgrep output
            if cppcheck_result.returncode == 0:
                error_message = cppcheck_result.stdout
                if error_message.strip():
                    result_array = extract_addresses(error_message, file_language)
                    print(result_array)
                    for result in result_array:
                        line_no_array = extract_numbers_before_pipe(result)
                        if line_no_array is None:
                            continue
                        for i in range(len(patch_old_line)):
                            for line_no in line_no_array:
                                if patch_old_line[i][0] <= line_no < patch_old_line[i][0] + patch_old_line[i][1]:
                                    is_find = True
                                    find_message.append(result)
                                    break
                            if is_find:
                                break
            else:
                print("Execute Error!", cppcheck_result.returncode, cppcheck_result.stderr)
                raise ValueError()

            #Save static analysis results
            if 'static' not in details[idx1]:
                details[idx1]['static'] = {}
            if 'semgrep' not in details[idx1]['static']:
                details[idx1]['static']['semgrep'] = []
            details[idx1]['static']['semgrep'] = [is_find, find_message]
            record_dict['details'] = details

    #Write updated record safely with lock
    with lock:
        with open(write_name, "a", encoding="utf-8") as rf:
            rf.write(json.dumps(record_dict) + '\n')

def func(language, file_name, write_name):
    """
    Executes parallel semgrep static analysis for all records in a given JSONL file.

    Parameters:
        language (str): Programming language of the analyzed files (e.g., 'c', 'cpp', 'java', 'python').
        file_name (str | Path): Path to the input JSONL file with merged vulnerability data.
        write_name (str | Path): Path to the output JSONL file to store analysis results.
    """
    with open(file_name, "r", encoding="utf-8") as r:
        content = r.readlines()

    #Use multiprocessing to speed up analysis
    with multiprocessing.Manager() as manager:
        lock = manager.Lock()
        with ProcessPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:
            futures = [
                executor.submit(process_content, lock, language, file_name, write_name, idx, content_line)
                for idx, content_line in enumerate(content)
            ]
            for future in concurrent.futures.as_completed(futures):
                future.result()

def main():
    """
    Main entry point for running semgrep-based static analysis across multiple languages.
    Executes analysis for C and C++ source code datasets and saves results.
    """
    #Run semgrep for C files
    language = "c"
    file_name = project_root / "Raw_Data_Crawling" / "github" / "merge_result_new" / "language" / "merge_C.jsonl"
    write_name = f"{module_path}/output/semgrep/merge_C_new.jsonl"
    func(language, file_name, write_name)
    print("Finished semgrep evaluation for C files")

    #Run semgrep for C++ files
    language = "cpp"
    file_name = project_root / "Raw_Data_Crawling" / "github" / "merge_result_new" / "language" / "merge_C.jsonl"
    write_name = f"{module_path}/output/semgrep/merge_C++_new.jsonl"
    func(language, file_name, write_name)
    print("Finished semgrep evaluation for C++ files")


if __name__ == "__main__":
    main()
