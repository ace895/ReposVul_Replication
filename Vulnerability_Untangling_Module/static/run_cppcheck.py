from pathlib import Path
import json
import re
import subprocess
import os
import shutil
from concurrent.futures import ProcessPoolExecutor
import concurrent.futures
import multiprocessing

#Set up project directories and paths
project_root = Path(__file__).resolve().parents[2]
module_path = project_root / "Vulnerability_Untangling_Module"
root_path =  module_path / "static"
data_path = project_root / "Raw_Data_Crawling" / "github" / "files_before"

def extract_addresses(input_string, file_path):
    """
    Extracts file path occurrences with line numbers from cppcheck output.

    Parameters:
        input_string (str): cppcheck stderr output
        file_path (str): path to the analyzed file

    Returns:
        list[str]: substrings containing matched file paths and messages
    """
    #Split cppcheck output into segments containing file paths
    pattern = rf'(?={re.escape(root_path)}/tmp/{file_path[6:].replace("/", "_")}(?:\.c|\.cpp|\.h):\d+)'
    result = re.split(pattern, input_string)
    result = [s for s in result if f'{root_path}/tmp/' in s]
    return result

def extract_number_from_string(input_string, file_path):
    """
    Extracts the line number from cppcheck output for a given file.

    Parameters:
        input_string (str): cppcheck output segment
        file_path (str): path to the analyzed file

    Returns:
        str or None: extracted line number or None if not found
    """
    #Use regex to find line number pattern in cppcheck message
    pattern = rf'{re.escape(root_path)}/tmp/{file_path[6:].replace("/", "_")}\.(c|h|cpp):(\d+):'
    match = re.search(pattern, input_string)

    if match:
        return match.group(2)
    else:
        return None

class TimeoutException(Exception):
    pass

def timeout_handler(signum, frame):
    raise TimeoutException("Function timed out")

def process_content(lock, language, file_name, write_name, idx, content_line):
    """
    Processes a single record from the JSONL file by running cppcheck on each file,
    checking if detected issues fall within modified lines, and saving results.

    Parameters:
        lock (threading.Lock): Lock object for thread-safe writing to output file.
        language (str): Programming language of the analyzed files (e.g., 'c', 'cpp', 'java').
        file_name (str | Path): Path to the input JSONL file containing code details and patches.
        write_name (str | Path): Path to the output JSONL file where analysis results are appended.
        idx (int): Index of the current record being processed, used for tracking progress.
        content_line (str): A single line from the JSONL file representing one record.

    Input files:
        Raw_Data_Crawling/github/files_before/<file_path> - original version of source code

    Output files:
        Vulnerability_Untangling_Module/output/cppcheck/<language>_new.jsonl - updated JSON with static analysis results
    """
    #Determine file extensions to check based on language
    if language == 'c':
        language_choice = ['c', 'h']
    elif language == 'cpp':
        language_choice = ['cpp', 'h', 'cc']
    elif language == 'java':
        language_choice = ['java']
    elif language == 'python':
        language_choice = ['py']

    #Parse the JSON line and extract patch details
    record_dict = json.loads(content_line)
    details = record_dict['details']
    
    #Iterate through files in the patch
    for idx1, detail in enumerate(details):
        if not detail['file_language'].lower().strip() in language_choice:
            continue

        #Extract key fields
        code = detail['code']
        code_before = detail['code_before']
        file_path = detail['file_path']
        file_language = detail['file_language']
        patch = detail['patch']

        #Identify modified line ranges from the patch
        pattern = re.compile(r'@@ -(\d+),?(\d*) \+(\d+),?(\d*) @@')
        matches = pattern.findall(patch)
        
        patch_old_line = []
        for match in matches:
            old_start, old_lines, new_start, new_lines = int(match[0]), match[1], int(match[2]), match[3]
            if old_lines == '':
                old_lines = 0
            else:
                old_lines = int(old_lines)

            if new_lines == '':
                new_lines = 0
            else:
                new_lines = int(new_lines)
            patch_old_line.append([old_start, old_lines])
            
        #Prepare paths for cppcheck
        real_path = '{}/{}'.format(data_path, file_path[6:]).replace('\\','/')
        safe_name = file_path[6:].replace('\\', '_').replace('/', '_')
        after_real_path = f"{root_path}//tmp//{safe_name}.{file_language}"

        #Skip if source file not found
        if not os.path.exists(real_path):
            print('No path exists!')
            continue

        #Copy source file to temporary analysis directory
        shutil.copy(real_path, after_real_path)

        #Run cppcheck if file is supported
        if file_language == 'py' or file_language == 'java' or file_language == 'c' or file_language == 'cc' or file_language == 'cpp' or file_language == 'h':
            is_find = False
            find_message = list()

            #Run cppcheck as subprocess
            cppcheck_result = subprocess.run(
                ["cppcheck", "--force", after_real_path],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                errors="ignore",
                timeout=10800
            )

            #Remove temp file after checking
            if os.path.exists(after_real_path):
                try:
                    os.remove(after_real_path)
                except Exception as e:
                    print(e)
                    pass

            #Parse cppcheck result for relevant errors
            try:
                if cppcheck_result.returncode == 0:
                    error_message = cppcheck_result.stderr
                    print("Command output:\n", cppcheck_result.stdout)
                    print("error output:\n", cppcheck_result.stderr)
                    if not error_message.strip() == '':
                        result_array = extract_addresses(error_message, file_path)
                        print(result_array)
                        for result in result_array:
                            print('------------------------')
                            print(result)
                            print(patch_old_line)
                            line_no = int(extract_number_from_string(result, file_path))
                            #Check if detected issue falls within modified lines
                            for i in range(len(patch_old_line)):
                                if line_no >= patch_old_line[i][0] and line_no < patch_old_line[i][0] + patch_old_line[i][1]:
                                    is_find = True
                                    find_message.append(result)
                                    print(result)
                else:
                    print('Execute Error!')
                    is_find = False
                    find_message = []
            except:
                print('Unkown Error!')
                            
            #Store cppcheck findings in JSON structure
            if 'static' not in details[idx1]:
                details[idx1]['static'] = dict()
            if 'cppcheck' not in details[idx1]['static']:
                details[idx1]['static']['cppcheck'] = list()
            details[idx1]['static']['cppcheck'] = [is_find, find_message]

            record_dict['details'] = details

    #Write updated record to output file with process lock
    with lock:
        with open(write_name, "a", encoding = "utf-8") as rf:
            rf.write(json.dumps(record_dict)+'\n')

def func(language, file_name, write_name):  
    """
    Orchestrates parallel processing of cppcheck analysis using multiple CPU cores.

    Input files:
        <module_path>/output/semgrep/merge_<language>_new.jsonl

    Output files:
        <module_path>/output/cppcheck/merge_<language>_new.jsonl
    """
    #Read all lines from the JSONL input file
    with open(file_name, "r",encoding = "utf-8") as r:
        content = r.readlines()

    #Create multiprocessing manager for synchronization
    with multiprocessing.Manager() as manager:
        lock = manager.Lock()
        #Execute cppcheck across all records concurrently
        with ProcessPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:
            futures = [
                executor.submit(process_content, lock, language, file_name, write_name, idx, content_line)
                for idx, content_line in enumerate(content)
            ]
            for future in concurrent.futures.as_completed(futures):
                processed_line = future.result()

def main():
    """
    Entry point for running cppcheck analysis on C and C++ files.

    Input files:
        Vulnerability_Untangling_Module/output/semgrep/merge_C_new.jsonl
        Vulnerability_Untangling_Module/output/semgrep/merge_cpp_new.jsonl

    Output files:
        Vulnerability_Untangling_Module/output/cppcheck/merge_C_new.jsonl
        Vulnerability_Untangling_Module/output/cppcheck/merge_cpp_new.jsonl
    """
    #Run cppcheck for C language files
    language = "c"
    file_name = f'{module_path}/output/semgrep/merge_C_new.jsonl' 
    write_name = f'{module_path}/output/cppcheck/merge_C_new.jsonl'  
    func(language, file_name, write_name)
    print("Finish cppcheck evaluation for C files")
    
    #Run cppcheck for C++ language files
    language = "cpp"
    file_name = f'{module_path}/output/semgrep/merge_cpp_new.jsonl'  
    write_name = f'{module_path}/output/cppcheck/merge_cpp_new.jsonl'  
    func(language, file_name, write_name)
    print("Finished cppcheck for C++ files")


if __name__ == "__main__":
    main()
